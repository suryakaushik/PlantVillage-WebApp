{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import Libraries\n"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "NA5gRqs6y97j"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing necessary libraries and modules required to build the classification model."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "VUGtqDPgSmZJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np  # multidimensional arrays\r\n",
    "import pickle   # converts python objects to byte streams\r\n",
    "import cv2 # computer vision and image processing\r\n",
    "import os # \r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from os import listdir\r\n",
    "from sklearn.preprocessing import LabelBinarizer\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers.normalization import BatchNormalization\r\n",
    "from keras.layers.convolutional import Conv2D\r\n",
    "from keras.layers.convolutional import MaxPooling2D\r\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\r\n",
    "from keras import backend as K\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from keras.optimizers import Adam\r\n",
    "from keras.preprocessing import image\r\n",
    "from keras.preprocessing.image import img_to_array\r\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "# from sklearn.metrics import confusion_matrix , classification_report\r\n",
    "# import pandas as pd\r\n"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AMUpYwh1HpCi",
    "outputId": "fdab74cb-e272-4bbb-8744-65c20088fb45"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Dataset"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "V_Chojawz3jw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initializing a few parameters required for the image dataset preprocessing."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "OyRk7kzTzOpO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Dimension of resized image\r\n",
    "DEFAULT_IMAGE_SIZE = tuple((256, 256))\r\n",
    "\r\n",
    "# Number of images used to train the model\r\n",
    "N_IMAGES = 100\r\n",
    "\r\n",
    "# Path to the dataset folder\r\n",
    "root_dir = 'D:\\Deep Learning Project\\Final Code\\dataset\\PlantVillage'\r\n",
    "\r\n",
    "train_dir = os.path.join(root_dir)\r\n",
    "val_dir = os.path.join(root_dir, 'val')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5eHthEdIBsr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use the function `convert_image_to_array` to resize an image to the size `DEFAULT_IMAGE_SIZE` we defined above."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "vyFL0dIxz-zk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def convert_image_to_array(image_dir):\r\n",
    "    try:\r\n",
    "        image = cv2.imread(image_dir)\r\n",
    "        if image is not None:\r\n",
    "            image = cv2.resize(image, DEFAULT_IMAGE_SIZE)   \r\n",
    "            return img_to_array(image)\r\n",
    "        else:\r\n",
    "            return np.array([])\r\n",
    "    except Exception as e:\r\n",
    "        print(f\"Error : {e}\")\r\n",
    "        return None"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WnCNrzC539qT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we load the training data images by traversing through all the folders and converting all the images and labels into separate lists respectively.\n",
    "\n",
    "*NOTE: We use a small portion of the entire dataset due to the computing limitations. Tweak `N_IMAGES` to include entire dataset.*"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "Q7uyGLRR1RaB"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "image_list, label_list = [], []\r\n",
    "\r\n",
    "try:\r\n",
    "    print(\"[INFO] Loading images ...\")\r\n",
    "    plant_disease_folder_list = listdir(train_dir)\r\n",
    "\r\n",
    "    for plant_disease_folder in plant_disease_folder_list:\r\n",
    "        print(f\"[INFO] Processing {plant_disease_folder} ...\")\r\n",
    "        plant_disease_image_list = listdir(f\"{train_dir}/{plant_disease_folder}/\")\r\n",
    "\r\n",
    "        for image in plant_disease_image_list[:N_IMAGES]:\r\n",
    "            image_directory = f\"{plant_disease_folder}/{image}\"\r\n",
    "            if image_directory.endswith(\".jpg\")==True or image_directory.endswith(\".JPG\")==True:\r\n",
    "                image_list.append(convert_image_to_array(image_directory))\r\n",
    "                label_list.append(plant_disease_folder)\r\n",
    "\r\n",
    "    print(\"[INFO] Image loading completed\")  \r\n",
    "except Exception as e:\r\n",
    "    print(f\"Error : {e}\")\r\n",
    "\r\n",
    "# Transform the loaded training image data into numpy array\r\n",
    "np_image_list = np.array(image_list, dtype=np.float16) / 225.0\r\n",
    "print()\r\n",
    "\r\n",
    "# Check the number of images loaded for training\r\n",
    "image_len = len(image_list)    #image-size\r\n",
    "print(f\"Total number of images: {image_len}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Processing Pepper__bell___Bacterial_spot ...\n",
      "[INFO] Processing Pepper__bell___healthy ...\n",
      "[INFO] Processing Potato___Early_blight ...\n",
      "[INFO] Processing Potato___healthy ...\n",
      "[INFO] Processing Potato___Late_blight ...\n",
      "[INFO] Processing Tomato_Bacterial_spot ...\n",
      "[INFO] Processing Tomato_Early_blight ...\n",
      "[INFO] Processing Tomato_healthy ...\n",
      "[INFO] Processing Tomato_Late_blight ...\n",
      "[INFO] Processing Tomato_Leaf_Mold ...\n",
      "[INFO] Processing Tomato_Septoria_leaf_spot ...\n",
      "[INFO] Processing Tomato_Spider_mites_Two_spotted_spider_mite ...\n",
      "[INFO] Processing Tomato__Target_Spot ...\n",
      "[INFO] Processing Tomato__Tomato_mosaic_virus ...\n",
      "[INFO] Processing Tomato__Tomato_YellowLeaf__Curl_Virus ...\n",
      "[INFO] Image loading completed\n",
      "\n",
      "Total number of images: 1500\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "colab_type": "code",
    "id": "MPaECpW13__5",
    "outputId": "7d88fa4b-9abb-4615-db7a-797b1cb5e926"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Examine the labels/classes in the training dataset. Map each label/class of image to a unique value of training task and save that mapping in a pkl file."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "WOzIsDNP3TWy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "label_binarizer = LabelBinarizer()\r\n",
    "image_labels = label_binarizer.fit_transform(label_list)\r\n",
    "\r\n",
    "pickle.dump(label_binarizer,open('plant_disease_label_transform.pkl', 'wb')) # saves all labels to disc\r\n",
    "n_classes = len(label_binarizer.classes_)\r\n",
    "\r\n",
    "print(\"Total number of classes: \", n_classes)\r\n",
    "print(label_binarizer.classes_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of classes:  15\n",
      "['Pepper__bell___Bacterial_spot' 'Pepper__bell___healthy'\n",
      " 'Potato___Early_blight' 'Potato___Late_blight' 'Potato___healthy'\n",
      " 'Tomato_Bacterial_spot' 'Tomato_Early_blight' 'Tomato_Late_blight'\n",
      " 'Tomato_Leaf_Mold' 'Tomato_Septoria_leaf_spot'\n",
      " 'Tomato_Spider_mites_Two_spotted_spider_mite' 'Tomato__Target_Spot'\n",
      " 'Tomato__Tomato_YellowLeaf__Curl_Virus' 'Tomato__Tomato_mosaic_virus'\n",
      " 'Tomato_healthy']\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jq5HO2SuILNk",
    "outputId": "182d992e-b353-4c79-b85f-5e4817bc3548"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Augment and Split Dataset"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "siSjS-jG77FH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using `ImageDataGenerator` to augment data by performing various operations(shift,rotation,zoom,flip) on the training images. To increase number of images in a dataset. Also it helps model to efficiently learn features from same image."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "G44Cdatx8VVN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# change data in real time when model is being trained\r\n",
    "augment = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\r\n",
    "                             height_shift_range=0.1, shear_range=0.2, \r\n",
    "                             zoom_range=0.2, horizontal_flip=True, \r\n",
    "                             fill_mode=\"nearest\")"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pbIYhnSFJkjp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting the data into training and test sets for validation purpose."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "aaoNWFDd8swl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(\"[INFO] Splitting data to train and test...\") # y is labels, x is data. if we do not specify particular random state, then everytime we run the code training and testing set will be different.\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] Splitting data to train and test...\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0Ls-TztoQlwD",
    "outputId": "fd39d4c6-26c0-465a-923c-d8044276d395"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Build Model\r\n"
   ],
   "outputs": [],
   "metadata": {
    "colab_type": "text",
    "id": "i4VNmekW4oEN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining the hyperparameters of the plant disease classification model."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "1QUHIVIcg6qI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "EPOCHS = 25 # number of times i pass data through model\r\n",
    "STEPS = 100\r\n",
    "LR = 1e-3  #Learning Rate -> \r\n",
    "BATCH_SIZE = 32\r\n",
    "WIDTH = 256\r\n",
    "HEIGHT = 256\r\n",
    "DEPTH = 3 # size of each Image array is 256x256x3"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BLZkDigJ9q4X"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating a sequential model and adding Convolutional, Normalization, Pooling, 25% Dropout(randomly turns off 25% neurons to reduce overfitting) and Activation layers at the appropriate positions.\r\n",
    "In this model, we are defaulting to \"channel_last\" architecture\r\n",
    "We create a 2D convolutional layer with 32 filters of 3x3 kernel and ReLu activation. We maintain output size same as input\r\n",
    "and then repeart with 64 and 128 filters."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "ZAlqxrJzha2n"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model = Sequential()\r\n",
    "inputShape = (HEIGHT, WIDTH, DEPTH)\r\n",
    "chanDim = -1\r\n",
    "\r\n",
    "if K.image_data_format() == \"channels_first\":\r\n",
    "    inputShape = (DEPTH, HEIGHT, WIDTH)\r\n",
    "    chanDim = 1\r\n",
    "\r\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\r\n",
    "model.add(Activation(\"relu\"))\r\n",
    "model.add(BatchNormalization(axis=chanDim))\r\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\r\n",
    "model.add(Dropout(0.25))                               #prevents from overfitting\r\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\r\n",
    "model.add(Activation(\"relu\"))\r\n",
    "model.add(BatchNormalization(axis=chanDim))\r\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\r\n",
    "model.add(Activation(\"relu\"))\r\n",
    "model.add(BatchNormalization(axis=chanDim))\r\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "model.add(Dropout(0.25))\r\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\r\n",
    "model.add(Activation(\"relu\"))                          # gives us output of a neural network layer\r\n",
    "model.add(BatchNormalization(axis=chanDim))\r\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\r\n",
    "model.add(Activation(\"relu\"))\r\n",
    "model.add(BatchNormalization(axis=chanDim))\r\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "model.add(Dropout(0.25))\r\n",
    "model.add(Flatten())\r\n",
    "model.add(Dense(1024))\r\n",
    "model.add(Activation(\"relu\"))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(Dropout(0.5))\r\n",
    "model.add(Dense(n_classes))             # its a fully connected layers with n_classes number of hidden units\r\n",
    "model.add(Activation(\"softmax\"))\r\n",
    "\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 85, 85, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 85, 85, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 85, 85, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 85, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 85, 85, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 85, 85, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 85, 85, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 85, 85, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 42, 42, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 42, 42, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 42, 42, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 42, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 42, 42, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 56448)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              57803776  \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                15375     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 15)                0         \n",
      "=================================================================\n",
      "Total params: 58,102,671\n",
      "Trainable params: 58,099,791\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "J_QFYYx8OVOb",
    "outputId": "102fba93-dd57-492e-9280-eec13f749d18"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train Model\n"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "ViKAhHPN5VMM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We initialize Adam optimizer with learning rate and decay parameters. We chose Adam, bcoz it performs faster and has global minimum convergence.\r\n",
    "\r\n",
    "Also, we choose the type of loss and metrics for the model and compile it for training."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "syZMhHG-iFlT"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Initialize optimizer to reduce losses\r\n",
    "opt = Adam(lr=LR, decay=LR / EPOCHS)\r\n",
    "\r\n",
    "# Compile model(distribution) --> binary cross entropy.i.e., gives yes or no output\r\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\r\n",
    "\r\n",
    "# Train model\r\n",
    "print(\"[INFO] Training network...\")\r\n",
    "\r\n",
    "import time\r\n",
    "t0=time.time()\r\n",
    "# each epoch takes definite number of images(= steps_per_epoch)\r\n",
    "history = model.fit_generator(augment.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='training' ),\r\n",
    "                              validation_data=(x_test, y_test),\r\n",
    "                              steps_per_epoch=len(x_train) // BATCH_SIZE,\r\n",
    "                              epochs=EPOCHS, \r\n",
    "                              verbose=1)\r\n",
    "print(\"training time:\", round(time.time()-t0, 3), \"s\")"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "PFRGnmHiO0Wt",
    "outputId": "410f8866-8786-4591-d71f-5a5c016e3ad9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate Model"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "d6gp-hPe9Rra"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Comparing the accuracy and loss by plotting the graph for training and validation."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "75wjEVZ-9Yab"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "acc = history.history['accuracy']\r\n",
    "val_acc = history.history['val_accuracy']\r\n",
    "loss = history.history['loss']\r\n",
    "val_loss = history.history['val_loss']\r\n",
    "epochs = range(1, len(acc) + 1)\r\n",
    "\r\n",
    "# Train and validation accuracy\r\n",
    "plt.plot(epochs, acc, 'b', label='Training accurarcy')\r\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accurarcy')\r\n",
    "plt.title('Training and Validation accurarcy')\r\n",
    "plt.legend()\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "\r\n",
    "# Train and validation loss\r\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\r\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\r\n",
    "plt.title('Training and Validation loss')\r\n",
    "plt.legend()\r\n",
    "plt.show()\r\n",
    "\r\n",
    "from keras.models import Model\r\n",
    "from keras.utils import plot_model\r\n",
    "plot_model(model,to_file='model.png') "
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "68DC4UqXTH4r",
    "outputId": "ba9057e9-7f06-48e9-db10-c198e7a52ad4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluating model accuracy by using the `evaluate` method. Training and validation accuracy are directly proportional and they become same after many epochs\r\n",
    "\r\n",
    "For better accuracy, use large datasets with better preprocessing or do more data augmentation, increase number of epochs and dropout to reduce overfitting, alter hyperparameters(learning rate,batch size,epochs)"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "BXO9rDqtNlDN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Training accuarcy > validation/test accuracy\r\n",
    "print(\"[INFO] Calculating model accuracy\")\r\n",
    "scores = model.evaluate(x_test, y_test)\r\n",
    "print(f\"Test Accuracy: {scores[1]*100}\")\r\n",
    "\r\n",
    "predictions = model.predict(x_test)\r\n",
    "y_preds = [np.argmax(i) for i in predictions]\r\n",
    "\r\n",
    "from sklearn import metrics\r\n",
    "print(metrics.confusion_matrix(y_test,y_preds))\r\n",
    "print(metrics.classification_report(y_test,y_preds))\r\n",
    "\r\n",
    "\r\n",
    "# import itertools\r\n",
    "\r\n",
    "# def plot_confusion_matrix (cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\r\n",
    "#     plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
    "#     plt.title(title)\r\n",
    "#     plt.colorbar()\r\n",
    "#     tick_marks = np.arange(len(classes))\r\n",
    "#     plt.xticks(tick_marks, classes, rotation=45)\r\n",
    "#     plt.yticks(tick_marks, classes)\r\n",
    "\r\n",
    "#     if normalize:\r\n",
    "#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n",
    "#         print(\"Normalized confusion matrix\")\r\n",
    "#     else:\r\n",
    "#         print('Confusion matrix, without normalization')\r\n",
    "\r\n",
    "#     print(cm)\r\n",
    "\r\n",
    "#     thresh = cm.max() / 2.\r\n",
    "#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
    "#         plt.text(j, i, cm[i, j],\r\n",
    "#             horizontalalignment=\"center\",\r\n",
    "#             color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
    "\r\n",
    "#     plt.tight_layout()\r\n",
    "#     plt.ylabel('True label')\r\n",
    "#     plt.xlabel('Predicted label')\r\n",
    "\r\n",
    "# def plot_hist(hist):\r\n",
    "#     plt.plot(hist.history[\"accuracy\"])\r\n",
    "#     plt.plot(hist.history[\"val_accuracy\"])\r\n",
    "#     plt.title(\"model accuracy\")\r\n",
    "#     plt.ylabel(\"accuracy\")\r\n",
    "#     plt.xlabel(\"epoch\")\r\n",
    "#     plt.legend([\"train\", \"validation\"], loc=\"upper left\")\r\n",
    "#     plt.show()\r\n",
    "\r\n",
    "# plot_hist(history)\r\n",
    "\r\n",
    "# def plot_hist_loss(hist):\r\n",
    "#     plt.plot(hist.history[\"loss\"])\r\n",
    "#     plt.plot(hist.history[\"val_loss\"])\r\n",
    "#     plt.title(\"model loss\")\r\n",
    "#     plt.ylabel(\"loss\")\r\n",
    "#     plt.xlabel(\"epoch\")\r\n",
    "#     plt.legend([\"train\", \"validation\"], loc=\"upper left\")\r\n",
    "#     plt.show()\r\n",
    "\r\n",
    "# plot_hist_loss(history)\r\n",
    "\r\n",
    "# plot_confusion_matrix(cm, SoilType, title= 'confusion matrix')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WlvFAyeuRQPK",
    "outputId": "9d775b2b-cdee-4e34-dda6-698fbce551b8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save Model"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "02FiJNWTN5J0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Dump pickle file of the model\r\n",
    "print(\"[INFO] Saving model...\")\r\n",
    "pickle.dump(model,open('plant_disease_classification_model.pkl', 'wb'))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "m84g3UW4RW0j",
    "outputId": "9972543b-0d1b-4a51-9a79-15564c874f9a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Dump pickle file of the labels\r\n",
    "print(\"[INFO] Saving label transform...\")\r\n",
    "filename = 'plant_disease_label_transform.pkl'\r\n",
    "image_labels = pickle.load(open(filename, 'rb'))"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UkzOGExsRe3I",
    "outputId": "3bb2d4f6-8384-418a-d6b2-669bafb82ee2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test Model\n"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "tRvKwCACObpp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We write the following `predict_disease` function to predict the class or disease of a plant image. \n",
    "\n",
    "We just need to provide the complete path to the image and it displays the image along with its prediction class or plant disease."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "ZKZcE-RmiuvH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def predict_disease(image_path):\r\n",
    "    t1=time.time()\r\n",
    "    image_array = convert_image_to_array(image_path)\r\n",
    "    np_image = np.array(image_array, dtype=np.float16) / 225.0\r\n",
    "    np_image = np.expand_dims(np_image,0)\r\n",
    "    plt.imshow(plt.imread(image_path))\r\n",
    "    result = model.predict_classes(np_image)\r\n",
    "    print((image_labels.classes_[result][0]))\r\n",
    "    print(\"predict time:\", round(time.time()-t1, 3), \"s\")"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uxhKVIETOuah"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For testing purposes, we randomly choose images from the dataset and try predicting class or disease of the plant image."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "93kbeqlSjCb-"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict_disease('/content/PlantVillage/val/Blueberry___healthy/008c85d0-a954-4127-bd26-861dc8a1e6ff___RS_HL 2431.JPG')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "w2Eq3ybER2dX",
    "outputId": "7247605d-b902-41a2-d4c5-6dceeca0d1ff"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict_disease('/content/PlantVillage/val/Potato___Early_blight/03b0d3c1-b5b0-48f4-98aa-f8904670290f___RS_Early.B 7051.JPG')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "Yx7zkdJWlLAz",
    "outputId": "f832bd93-c1cc-4187-dd6b-20917be315bf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict_disease('/content/PlantVillage/val/Tomato___Target_Spot/1006b3dd-22d8-41b8-b83d-08bf189fcdaa___Com.G_TgS_FL 8118.JPG')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "PJb3gtAWlgJW",
    "outputId": "d043d0a0-9fda-4f72-e41c-1a7eb003c9a9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict_disease('/content/PlantVillage/val/Orange___Haunglongbing_(Citrus_greening)/02459e0c-a189-4dc9-a0dc-0548e36d0efb___CREC_HLB 5714.JPG')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "6SVSwms_ln3B",
    "outputId": "0c90e96a-fd53-4382-daac-e16690dce936"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reuse Model"
   ],
   "metadata": {
    "colab_type": "text",
    "id": "3EMeS2AZPqwf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing necessary libraries and modules required to build the classification model."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "ZqTsg-ZskDvE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\r\n",
    "import pickle\r\n",
    "import cv2\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from os import listdir\r\n",
    "from sklearn.preprocessing import LabelBinarizer\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers.normalization import BatchNormalization\r\n",
    "from keras.layers.convolutional import Conv2D\r\n",
    "from keras.layers.convolutional import MaxPooling2D\r\n",
    "from keras.layers.core import Activation, Flatten, Dropout, Dense\r\n",
    "from keras import backend as K\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from keras.optimizers import Adam\r\n",
    "from keras.preprocessing import image\r\n",
    "from keras.preprocessing.image import img_to_array\r\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "from PIL import Image\r\n",
    "import matplotlib.image as iplot"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "DLL load failed: The specified module could not be found.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-86cf0364f762>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found."
     ]
    }
   ],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FuyQWhlqj-jz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the trained model and its labels for prediction."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "j5XLJbmKQiJE"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Load model\r\n",
    "filename = 'plant_disease_classification_model.pkl'\r\n",
    "model = pickle.load(open(filename, 'rb'))\r\n",
    "\r\n",
    "# Load labels\r\n",
    "filename = 'plant_disease_label_transform.pkl'\r\n",
    "image_labels = pickle.load(open(filename, 'rb'))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-687ef9bf7cf6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'plant_disease_classification_model.pkl'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Load labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_BpNjfQmgHI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use the `convert_image_to_array` function to resize an image and `predict_disease` function to predict the class or disease of a plant image.\n",
    "\n",
    "We just need to provide the complete path to the image and it displays the image along with its prediction class or plant disease."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "8KFhgotClJv8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Dimension of resized image\r\n",
    "DEFAULT_IMAGE_SIZE = tuple((256, 256))\r\n",
    "\r\n",
    "def convert_image_to_array(image_dir):\r\n",
    "    try:\r\n",
    "        image = cv2.imread(image_dir)\r\n",
    "        if image is not None:\r\n",
    "            image = cv2.resize(image, DEFAULT_IMAGE_SIZE)   \r\n",
    "            return img_to_array(image)\r\n",
    "        else:\r\n",
    "            return np.array([])\r\n",
    "    except Exception as e:\r\n",
    "        print(f\"Error : {e}\")\r\n",
    "        return None\r\n",
    "\r\n",
    "def predict_disease(image_path):\r\n",
    "    image_array = convert_image_to_array(image_path)\r\n",
    "    np_image = np.array(image_array, dtype=np.float16) / 225.0\r\n",
    "    np_image = np.expand_dims(np_image,0)\r\n",
    "    plt.imshow(plt.imread(image_path))\r\n",
    "    result = model.predict_classes(np_image)\r\n",
    "    print((image_labels.classes_[result][0]))\r\n",
    "    #itemindex = np.where(result==np.max(result))\r\n",
    "    #print(\"probability:\"+str(np.max(result))+\"\\n\"+label_binarizer.classes_[itemindex[1][0]])\r\n",
    "\r\n",
    "    img = Image.open(image_path)\r\n",
    "    plt.imshow(iplot.imread(image_path))\r\n",
    "    plt.title('Leaf')\r\n",
    "    plt.xlabel((image_labels.classes_[result][0]))\r\n",
    "    plt.xticks([])\r\n",
    "    plt.yticks([])\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WTErOo1jigq"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predict disease of any plant image."
   ],
   "metadata": {
    "colab_type": "text",
    "id": "d6BO6sPyQx-p"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict_disease('/content/PlantVillage/val/Corn_(maize)___Northern_Leaf_Blight/028159fc-995e-455a-8d60-6d377580a898___RS_NLB 4023.JPG')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "LXnqW4w3mkLA",
    "outputId": "7022dace-353f-4ee8-b51c-ea45ab7956ab"
   }
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Plant Disease Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('kaggleenv': conda)",
   "name": "python3710jvsc74a57bd0f14c19cbe434d128ed0d774614aebe12c652b16f96613f1e3048127cb744b81a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "f14c19cbe434d128ed0d774614aebe12c652b16f96613f1e3048127cb744b81a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}